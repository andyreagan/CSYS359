\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage{graphicx}
\usepackage{listings,color}
\usepackage{setspace}

\lstset{language=matlab,
        basicstyle=\ttfamily\scriptsize\singlespacing,
        keywordstyle=\color{blue},
        stringstyle=\color{red},
        commentstyle=\color{green},
        morecomment=[l][\color{magenta}]{\#},
        frame=L,
        xleftmargin=\parindent,
        numbersep=5pt,
        breaklines=true,
        breakatwhitespace=false,
        escapeinside={\%*}{*)},
}

\setlength{\parindent}{0cm}

\setlength{\parskip}{1mm}

\begin{document}

\title{\vspace{-2cm}Homework 2: Simple Hopfield Net}
\author{Andy Reagan}

\maketitle

\section{Discussion}

After coding up the Hopfield network, which is very simple once I'm done, I have to say that I had a lot of trouble getting the details right.
There is a gap between the details given in the literature and the exact coding of this that I seemed to miss, but I do think that I have a working code.
At least, it gets the training correctly and settles down for the other inputs that I tested.

The core of the Hopfield network being useful seems to be that it monotonically decreases the energy function given, such that any solution is gauranteed to be a local optimal solution.
Techniques like annealing attempt to search the energy space more broadly.
So, finding an appropriate energy (Liapunov) function which is minimized by the network and then being able to solve the gradient of that to find the weights is the hard part, and it seems like others have been able to find energy functions which are suitable for solving problems of interest.

%% \begin{align*} 0 = -\frac{\epsilon}{h^2} + \frac{hf'''(x)}{3}\end{align*}

%% \begin{figure}[h!]
%%  \centering
%%   \includegraphics[width=0.79\textwidth]{part1-1.png}
%%   \label{fig:1}
%% \end{figure}

\clearpage
\pagebreak

\section*{Full code}

\lstinputlisting[]{hopfield_andy_driver.m}

\end{document}
